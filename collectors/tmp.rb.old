#!/usr/bin/ruby

class Parser

  def initialize
    @video = ["ogv", "mpg", "mpeg", "avi", "mp4", "m4v", "mov", "flv", "ogg"]
  end

  def parse_vimeo(id)
    @fields = {}
    url = "http://vimeo.com/moogaloop/load/clip:#{id}"
    data = open(url)
    doc = Nokogiri::XML(data)
    title = doc.xpath('//caption')[0].content
    sig = doc.xpath('//request_signature')[0].content
    sig_exp = doc.xpath('//request_signature_expires')[0].content
    url2 = "http://vimeo.com/moogaloop/play/clip:#{id}/#{sig}/sig_exp/"
    # send url2 to download, must handle redirect
    @fields = {:title => title, :url = url2}
    return @fields
  end

  def parse_internet_archive(url)
    @files = []
    @fields = {}
    found = false
    data = open(url)
    doc = Nokogiri::HTML(data)
    # title not properly parsed, needs regex
    title = doc.xpath('//title')[0].content
    description = doc.xpath('//meta[@name="description"]/@content')[0].value
    # could also pull tags from keywords
    doc.xpath('//table[@class="fileFormats"]/tr/td/a').each do |a|
      link = doc.xpath("#{a.path}/@href")[0].value
      ext = doc.xpath("#{a.path}/@href")[0].value.match(/[a-z]+(?=$)/)
      # convert all file sizes to bytes
      size_string = doc.xpath("#{a.path}")[0].content
      size_string = size_string.match(/([\d.]+)\s?(KB|MB|GB)/)
     if size_string[2] == "GB"
        size = size_string[1].to_f * 1073741824
      elsif size_string[2] == "MB"
        size = size_string[1].to_f * 1048576
      elsif size_string[2] == "KB"
        size = size_string[1].to_f * 1024
      else
        size = size_string[1].to_f
      end
      files_tmp = {:ext => ext, :size => size, :link => link}
      @files.push(files_tmp)
    end
    # determine which is the smallest video file
    filesize = 0
    @files = @files.sort_by {|e| e[:size]}
    @files.each do |e|
     if @video.include?(e[:ext].to_s)
        url = "http://www.archive.org#{e[:link]}"
        filesize = e[:size].to_i
        found = true
        break
      end
    end
    if found
      @fields = {:title => title, :description => description, :url => url, :size => filesize}
    else
      return false
    end
  end

  def parse_internet_archive_search(query=false, page=1)
    if query == false
      url = 'http://www.archive.org/search.php?sort=-publicdate&query=%28mediatype%3A%28MovingImage%29%29%20AND%20%28format%3Ampeg%20OR%20format%3Aquicktime%20OR%20format%3Areal%29&page=' + "#{page}"
    else
      url = "http://www.archive.org/search.php?query=#{query}"
    end
    data = open(url)
    doc = Nokogiri::HTML(data)
    urls = []
    doc.xpath('//a[@class="titleLink"]/@href').each {|u| urls.push("http://www.archive.org#{u}")}
    return urls
  end
  
  def parse_wikimedia(url="http://commons.wikimedia.org/wiki/Special:Random/File")
    data = open(url, "User-Agent" => "Ruby/#{RUBY_VERSION}")
    doc = Nokogiri::HTML(data)
    ext = doc.xpath('//title')[0].content.match(/[a-z]+(?= - Wikimedia Commons$)/)[0]
#    $ig_logger.debug "COLLECTORS: PARSER: PARSE_WIKIMEDIA: EXT: #{ext}"
    if @video.include?(ext)
      return self.parse_wikimedia_video(doc)
    else
#      $ig_logger.error "COLLECTORS: PARSER: PARSE_WIKIMEDIA: UNSUPPORTED FILE TYPE: #{ext}"
      return false
    end
  end

  def parse_wikimedia_image(doc)
    url = doc.xpath('//div[@id="file"]/a/img/@src')[0].value
    title = doc.xpath('//div[@id="file"]/a/img/@alt')[0].value.match(/[^File:].*$/)[0]
    width = doc.xpath('//div[@id="file"]/a/img/@width')[0].value
    height = doc.xpath('//div[@id="file"]/a/img/@height')[0].value
    return {:url => url, :title => title, :width => width, :height => height}
  end

  def parse_wikimedia_video(doc)
    url = doc.xpath('//div[@class="fullMedia"]/p/a/@href')[0].value
    title = doc.xpath('//div[@class="fullMedia"]/p/a/@title')[0].value
    return {:url => url, :title => title}
  end

  def parse_wikimedia_gallery(url="http://commons.wikimedia.org/wiki/Special:NewFiles")
    data = open(url, "User-Agent" => "Ruby/#{RUBY_VERSION}")    
    doc = Nokogiri::HTML(data)
    urls = []
    doc.xpath('//div[@class="gallerybox"]/div[@class="gallerytext"]/a[1]/@href').each {|u| urls.push("http://commons.wikimedia.org#{u}")}
    return urls
  end

end

class Grabber

  def download(url)
    # split base and file from url
    parts = URI.split(url)
    base = parts[2].match(/([a-zA-Z0-9]+\.[a-zA-Z]+$)/)[1]
    path = parts[5]
    filename = path.match(/(^.*\/)(.*)/)[2]
    begin
      Net::HTTP.get_response URI.parse(url) do |response|
        if response['Location']!=nil
          puts "REDIRECT TO: #{response['Location']}"
          return download(response['Location'])
        end
        raise "No body in http response" if response.body == ''
        open("./tmp/#{filename}", "wb") do |file|
          file.write(response.read_body)
        end
      end
#      $ig_logger.debug "COLLECTORS: GRABBER: DOWNLOAD_FILE: SIZE #{size} bytes"
      return true
    rescue Exception => e
      $ig_logger.error "#{e.message}"
      $ig_logger.error "COLLECTORS: GRABBER: DOWNLOAD_FILE: START: FAILED"
      return false
    end
  end

end
